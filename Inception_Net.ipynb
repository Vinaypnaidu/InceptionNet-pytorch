{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception Net using Pytorch\n",
    "\n",
    "This tutorial will teach you how to implement the original Inception Net proposed in [Going deeper with convolutions](https://arxiv.org/abs/1409.4842) by Szegedy _et al._ using PyTorch. The Inception Net architecture won the ImageNet classification challenge in 2014. If you are new to PyTorch I would recommend going through this [tutorial](https://github.com/Vinaypnaidu/deep-learning-essentials) first. It covers some Deep Learning basics and explains how to build an end-to-end image classification project using the CIFAR-10 dataset.<br>\n",
    "\n",
    "The architecture of Inception Net is slightly different when compared to normal ConvNets. It uses the **Inception module** with feature concatenations and also has two **Auxiliary classifiers** branching out from the main stem. Hence this project will give you a solid experience of converting a paper to code, and also a good understanding of building models using PyTorch. I would suggest referring the original paper while going through this tutorial. (particularly table 1)\n",
    "\n",
    "![](./images/google-net.png)\n",
    "\n",
    "Fun fact: This first version of Inception Net is also called GoogLeNet as an homage to the original LeNet 5 architecture by LeCun _et al._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T16:15:30.294994Z",
     "iopub.status.busy": "2023-08-20T16:15:30.294533Z",
     "iopub.status.idle": "2023-08-20T16:15:30.303297Z",
     "shell.execute_reply": "2023-08-20T16:15:30.301006Z",
     "shell.execute_reply.started": "2023-08-20T16:15:30.294958Z"
    },
    "id": "npb4z_h_PtHe"
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4fHpkHMCyjC"
   },
   "source": [
    "## Building the Inception Module\n",
    "\n",
    "The Inception Module has 4 branches containing conv and pool operations. The number of input and output channels in each layer are indicated by the parameter: `block_params`. Necessary padding is applied to preserve the spatial dimensions.\n",
    "1. Branch 1: `1x1` conv\n",
    "2. Branch 2: `1x1` conv (aka reduction) followed by `3x3` conv\n",
    "3. Branch 3: `1x1` conv (aka reduction) followed by `5x5` conv\n",
    "4. Branch 4: `3x3` maxpool, followed by `1x1` conv\n",
    "\n",
    "<div style=\"width: 25%; height: auto;\">\n",
    "    <img src=\"./images/inception.png\" alt=\"Inception Block Architecture\" style=\"width: 100%; height: 100%;\">\n",
    "</div>\n",
    "\n",
    "The `Inception_Block` class, subclasses the neural network module: `nn.Module` provided by PyTorch, It is a very powerful and flexible API to build neural network architectures. We need to implement the following methods: \n",
    "1. `__init__`: Responsible for initializing the layers in the neural network or module. These include conv, pool and other operations. \n",
    "2. `forward`: Responsible for implementing the forward propagation of the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T16:10:58.057027Z",
     "iopub.status.busy": "2023-08-20T16:10:58.056634Z",
     "iopub.status.idle": "2023-08-20T16:10:58.067889Z",
     "shell.execute_reply": "2023-08-20T16:10:58.066488Z",
     "shell.execute_reply.started": "2023-08-20T16:10:58.056999Z"
    },
    "id": "C9fHsot0ZCyA"
   },
   "outputs": [],
   "source": [
    "class Inception_Block(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements the Inception block from the original paper. Takes a tuple\n",
    "    block_params = (in_ch, out1, red2, out2, red3, out3, out4) to initialize\n",
    "    the block. Outputs a volume (N, C, H, W) based on block_params.\n",
    "    \"\"\"\n",
    "    def __init__(self, block_params):\n",
    "        super().__init__()\n",
    "        in_ch, out1, red2, out2, red3, out3, out4 = block_params\n",
    "\n",
    "        # branch 1: 1x1 conv\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_ch, out_channels=out1, kernel_size=1)\n",
    "\n",
    "        # branch 2: reduce - 3x3 conv\n",
    "        self.reduce2 = nn.Conv2d(in_channels=in_ch, out_channels=red2, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=red2, out_channels=out2, kernel_size=3, padding=1)\n",
    "\n",
    "        # branch 3: reduce - 5x5 conv\n",
    "        self.reduce3 = nn.Conv2d(in_channels=in_ch, out_channels=red3, kernel_size=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=red3, out_channels=out3, kernel_size=5, padding=2)\n",
    "\n",
    "        # branch 4: maxpool - 1x1 conv\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=in_ch, out_channels=out4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = F.relu(self.conv1(x))\n",
    "        conv2_out = F.relu(self.conv2(F.relu(self.reduce2(x))))\n",
    "        conv3_out = F.relu(self.conv3(F.relu(self.reduce3(x))))\n",
    "        conv4_out = F.relu(self.conv4(self.maxpool4(x)))\n",
    "        output = (conv1_out, conv2_out, conv3_out, conv4_out)\n",
    "        output = torch.cat(output, axis=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T16:10:58.307023Z",
     "iopub.status.busy": "2023-08-20T16:10:58.306639Z",
     "iopub.status.idle": "2023-08-20T16:10:59.132068Z",
     "shell.execute_reply": "2023-08-20T16:10:59.131145Z",
     "shell.execute_reply.started": "2023-08-20T16:10:58.306999Z"
    },
    "id": "3_ulpE74o1Yg",
    "outputId": "5774d789-9633-4b28-b9d0-7c360f81be21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256, 32, 32])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# verify output shape for inception (3a) block in the paper\n",
    "in_ch, out1, red2, out2, red3, out3, out4 = 192, 64, 96, 128, 16, 32, 32\n",
    "out_ch = out1 + out2 + out3 + out4\n",
    "\n",
    "block_params = (in_ch, out1, red2, out2, red3, out3, out4)\n",
    "block = Inception_Block(block_params)\n",
    "\n",
    "x = torch.zeros((64, in_ch, 32, 32)) # (N, C, H, W)\n",
    "print(block(x).shape)\n",
    "print(block(x).shape[1] == out_ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3gi5jFkDEyq"
   },
   "source": [
    "## Building the Auxiliary Classifier\n",
    "\n",
    "The GoogLeNet architecture features two auxiliary classifiers, which branch out from the main classifier. They are small feed forward networks with the following layers:\n",
    "1. `5x5` avg pool\n",
    "2. `1x1` conv\n",
    "3. Fully connected layer with 1024 units\n",
    "4. Dropout layer that keeps 30% of the units\n",
    "5. Fully connected layer with `num_classes` units\n",
    "<br>\n",
    "\n",
    "<div style=\"width: 40%; height: auto;\">\n",
    "    <img src=\"./images/auxiliary.png\" alt=\"Auxiliary Classifier\" style=\"width: 100%; height: 100%;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T16:10:59.635002Z",
     "iopub.status.busy": "2023-08-20T16:10:59.634637Z",
     "iopub.status.idle": "2023-08-20T16:10:59.642961Z",
     "shell.execute_reply": "2023-08-20T16:10:59.641679Z",
     "shell.execute_reply.started": "2023-08-20T16:10:59.634976Z"
    },
    "id": "YBOuT1e-Z1Za"
   },
   "outputs": [],
   "source": [
    "class Auxiliary_Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements the auxiliary classifier from the original paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, num_classes):\n",
    "        super().__init__()\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=5, stride=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=in_ch, out_channels=128, kernel_size=1)\n",
    "        self.fc3 = nn.Linear(4*4*128, 1024)\n",
    "        self.dropout4 = nn.Dropout(p=0.7)\n",
    "        self.fc5 = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avgpool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.fc3(x.reshape(x.shape[0], -1)))\n",
    "        x = self.dropout4(x)\n",
    "        scores = self.fc5(x)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T16:11:00.352752Z",
     "iopub.status.busy": "2023-08-20T16:11:00.351809Z",
     "iopub.status.idle": "2023-08-20T16:11:00.450468Z",
     "shell.execute_reply": "2023-08-20T16:11:00.449240Z",
     "shell.execute_reply.started": "2023-08-20T16:11:00.352710Z"
    },
    "id": "HqBs0Bn3g1z-",
    "outputId": "96b6e966-3603-4292-8b89-e9369ae9a2ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1000])\n"
     ]
    }
   ],
   "source": [
    "in_ch, num_classes = 512, 1000\n",
    "aux_classifier = Auxiliary_Classifier(in_ch, num_classes)\n",
    "x = torch.zeros((64, 512, 14, 14)) # from inception 4a (Table 1)\n",
    "print(aux_classifier(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgEwrl3iDbqh"
   },
   "source": [
    "## Building the Inception Net Model\n",
    "\n",
    "Similar to `Inception_Block` and `Auxiliary_Classifier`, `Inception_Net` subclasses `nn.Module`. \n",
    "\n",
    "1. The `__init__` method will initialize the entire architecture. We store the `block_params` for each Inception block in `self.inception_params`. \n",
    "2. The `forward` method will compute the scores from the main and auxiliary classifiers. We store a copy of the outputs from Inception blocks `inception4a` and `inception4d` to compute the outputs of the auxiliary classifiers. Finally we return the scores of all 3 classifiers.  You can convince yourself about the implementation by referring  table 1 from the official paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T16:11:02.586760Z",
     "iopub.status.busy": "2023-08-20T16:11:02.586395Z",
     "iopub.status.idle": "2023-08-20T16:11:02.603166Z",
     "shell.execute_reply": "2023-08-20T16:11:02.601985Z",
     "shell.execute_reply.started": "2023-08-20T16:11:02.586730Z"
    },
    "id": "w0jLgdHZpjkJ"
   },
   "outputs": [],
   "source": [
    "class Inception_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements the original Inception net from the paper. Expected input shape\n",
    "    is (N, 3, 224, 224). Outputs class scores of shape (N, num_classes).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # from Table 1 in the paper\n",
    "        self.inception_params = {\n",
    "            'inception3a': (192, 64, 96, 128, 16, 32, 32),\n",
    "            'inception3b': (256, 128, 128, 192, 32, 96, 64),\n",
    "            'inception4a': (480, 192, 96, 208, 16, 48, 64),\n",
    "            'inception4b': (512, 160, 112, 224, 24, 64, 64),\n",
    "            'inception4c': (512, 128, 128, 256, 24, 64, 64),\n",
    "            'inception4d': (512, 112, 144, 288, 32, 64, 64),\n",
    "            'inception4e': (528, 256, 160, 320, 32, 128, 128),\n",
    "            'inception5a': (832, 256, 160, 320, 32, 128, 128),\n",
    "            'inception5b': (832, 384, 192, 384, 48, 128, 128),\n",
    "        }\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.reduce2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.inception3a = Inception_Block(self.inception_params['inception3a'])\n",
    "        self.inception3b = Inception_Block(self.inception_params['inception3b'])\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.inception4a = Inception_Block(self.inception_params['inception4a'])\n",
    "        self.inception4b = Inception_Block(self.inception_params['inception4b'])\n",
    "        self.inception4c = Inception_Block(self.inception_params['inception4c'])\n",
    "        self.inception4d = Inception_Block(self.inception_params['inception4d'])\n",
    "        self.inception4e = Inception_Block(self.inception_params['inception4e'])\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.inception5a = Inception_Block(self.inception_params['inception5a'])\n",
    "        self.inception5b = Inception_Block(self.inception_params['inception5b'])\n",
    "        self.avgpool5 = nn.AvgPool2d(kernel_size=7, stride=1)\n",
    "        self.dropout5 = nn.Dropout(p=0.4)\n",
    "        self.linear5 = nn.Linear(1024, num_classes)\n",
    "\n",
    "        # Auxiliary classifiers\n",
    "        self.aux_classifier1 = Auxiliary_Classifier(512, num_classes)\n",
    "        self.aux_classifier2 = Auxiliary_Classifier(528, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.maxpool1(x)\n",
    "        x = F.relu(self.conv2(F.relu(self.reduce2(x))))\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.inception4a(x)\n",
    "        aux0 = x.clone() # for auxiliary branch connected to 4a\n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        aux1 = x.clone() # for auxiliary branch connected to 4d\n",
    "        x = self.inception4e(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "        x = self.avgpool5(x)\n",
    "        x = self.dropout5(x.reshape(x.shape[0], -1))\n",
    "        # main branch scores\n",
    "        scores2 = self.linear5(x)\n",
    "        # auxiliary classifiers\n",
    "        scores0 = self.aux_classifier1(aux0)\n",
    "        scores1 = self.aux_classifier2(aux1)\n",
    "        return (scores0, scores1, scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T16:11:03.035285Z",
     "iopub.status.busy": "2023-08-20T16:11:03.034905Z",
     "iopub.status.idle": "2023-08-20T16:11:06.297269Z",
     "shell.execute_reply": "2023-08-20T16:11:06.296017Z",
     "shell.execute_reply.started": "2023-08-20T16:11:03.035256Z"
    },
    "id": "NBhHVbJqpFG8",
    "outputId": "0fc4f765-088e-4080-b530-cc324841bfc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1000])\n",
      "torch.Size([64, 1000])\n",
      "torch.Size([64, 1000])\n"
     ]
    }
   ],
   "source": [
    "# check output shape\n",
    "x = torch.zeros((64, 3, 224, 224))\n",
    "model = Inception_Net(num_classes=1000)\n",
    "for scores in model(x):\n",
    "    print(scores.shape) # should see [64, 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss computation \n",
    "\n",
    "In the original paper, even the auxiliary classifiers contibute partially to the overall loss. The total loss is calculated as follows, which is then backpropagated through the entire network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-20T16:11:19.615822Z",
     "iopub.status.busy": "2023-08-20T16:11:19.615248Z",
     "iopub.status.idle": "2023-08-20T16:11:19.631534Z",
     "shell.execute_reply": "2023-08-20T16:11:19.630501Z",
     "shell.execute_reply.started": "2023-08-20T16:11:19.615786Z"
    },
    "id": "Txi2bAId5HIE"
   },
   "outputs": [],
   "source": [
    "scores0, scores1, scores2 = model(x)\n",
    "aux_loss1 = F.cross_entropy(scores0, y) # auxiliary loss 1\n",
    "aux_loss2 = F.cross_entropy(scores1, y) # auxiliary loss 2\n",
    "main_loss = F.cross_entropy(scores2, y) # main loss\n",
    "\n",
    "# calculate weighted loss according to paper\n",
    "total_loss = main_loss + (0.3 * aux_loss1) + (0.3 * aux_loss2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advice: If you get some errors while building the model or a part of it, try printing the shape of the output tensor after each layer and verify that it matches. \n",
    "\n",
    "That is it. You now know how to implement the original Inception Net paper using PyTorch. I would suggest exploring and implementing the latter versions of Inception Net as a fun exercise :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
